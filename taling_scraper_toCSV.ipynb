{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "count = 0\n",
    "main_link = 'https://taling.me/Home/Search/'\n",
    "query = '?page={}&cateMain={}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드가 복잡해서 객체지향으로 구현\n",
    "class TalingScraper():\n",
    "    def __init__(self, key, courses): #카테고리ID, 검색된 코스 수를 파라미터로 입력\n",
    "        self.key = key\n",
    "        self.pages = (int(courses)//15)+1 #페이지 수 수집\n",
    "        self.main_link = 'https://taling.me/Home/Search/'\n",
    "        self.query = '?page={}&cateSub={}'\n",
    "        \n",
    "    def scrap_info(self):\n",
    "        key = self.key\n",
    "        pages = self.pages\n",
    "        main_link = self.main_link\n",
    "        query = self.query\n",
    "        titles = []\n",
    "        enrolls = []\n",
    "        links = []\n",
    "        for i in range(1, pages+1): #페이지 순회하며 title, link, enroll 정보 수집\n",
    "            res = requests.get((main_link + query).format(i,key))\n",
    "            html = res.text\n",
    "            soup = BeautifulSoup(html,'lxml')\n",
    "            temp = soup.select('.cont2_box .cont2_class')\n",
    "            titles.append([title.select_one('div.title').text.strip() for title in temp])\n",
    "            links.append([main_link+link.a['href'] for link in temp])\n",
    "            enrolls.append([enroll.select_one('div.d_day').text.strip()[:-4] \\\n",
    "                            if '참여' in enroll.select_one('div.d_day').text else 0\\\n",
    "                            for enroll in temp\n",
    "                           ])\n",
    "            print('진행률 = {} / {}'.format(i, pages))\n",
    "        titles = sum(titles, [])\n",
    "        links = sum(links, [])\n",
    "        enrolls = sum(enrolls, [])\n",
    "        print('링크 수집이 완료되었습니다.')\n",
    "        return titles, enrolls, links\n",
    "\n",
    "    def scrap_price(self, titles,links): # 가격 정보는 상세페이지에서 확인할 수 있습니다. 모든 링크를 순회하며 가격 정보를 수집합니다.\n",
    "        links = links\n",
    "        titles = titles\n",
    "        count = 0\n",
    "        prices_perH = []\n",
    "        prices = []\n",
    "        print('도서 수집을 시작합니다.')\n",
    "        for link in links:\n",
    "            count += 1\n",
    "            res = requests.get(link)\n",
    "            html = res.content\n",
    "            soup = BeautifulSoup(html,'lxml')\n",
    "                \n",
    "            prices_perH.append(soup.select_one('p.price_info > span.per').text[:-6])\n",
    "            prices.append(soup.select_one('p.price_info > span.total > b').text[:-3])\n",
    "            print(\"클레스명 : {} | 진행률 : {}/{}\".format(titles[count-1], count, len(links)))\n",
    "        print('클레스 가격 정보 수집이 완료되었습니다.')\n",
    "        return prices_perH,prices\n",
    "\n",
    "    def make_df(self, name, links, titles, enrolls, prices, prices_perH): # 모든 데이터로 데이터프레임을 생성합니다.\n",
    "        df = pd.DataFrame({'링크': links, '강좌명': titles, '등록수': enrolls, '가격': prices,\\\n",
    "                           '시간당 단가': prices_perH})\n",
    "        df.to_csv('./{}.csv'.format(name))\n",
    "        print('도서 리스트를 csv파일로 저장하였습니다. 저장 경로는 현재 실행 위치입니다.')\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scraper = TalingScraper(11, 52) # test param->(id, 코스 수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진행률 = 1 / 4\n",
      "진행률 = 2 / 4\n",
      "진행률 = 3 / 4\n",
      "진행률 = 4 / 4\n",
      "링크 수집이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "titles, enrolls, links = Scraper.scrap_info() # return된 값을 변수로 받아냅니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 수가 일치하는지(중간에 누락된 값이 없는지) 확인합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enrolls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도서 수집을 시작합니다.\n",
      "클레스명 : [3월모집] 1도 모른 나, 6주 후 실무 쿼리를 작성하다니!   #데이터베이스(SQL) 입문부터 실무까지 | 진행률 : 1/57\n",
      "클레스명 : [3월 원데이 모집 중] 비전공자도 즉시 써먹는 데이터분석 & 시각화 실습! 'R' | 진행률 : 2/57\n",
      "클레스명 : [SQL] 쉽게 배우는 실무 데이터분석! 기초부터 현업사례까지! | 진행률 : 3/57\n",
      "클레스명 : 서울대 출신 경제학 박사가 가르치는 딥러닝 예측방법론 | 진행률 : 4/57\n",
      "클레스명 : [파워비아이공방/기초반]일반 Excel유저를 위한 Power BI 강의 (by 현직컨설턴트 | 진행률 : 5/57\n",
      "클레스명 : [2021년 2월3월/정규반 모집중! 입문자 R데이터 분석]  단계적으로 배우는 R 패키지 | 진행률 : 6/57\n",
      "클레스명 : 엑셀 및 R로 이해하는 통계적 분석 (수강자 맞춤형 진행 가능) | 진행률 : 7/57\n",
      "클레스명 : 네이버 API 활용하기 + 트렌드 데이터 시각화 | 진행률 : 8/57\n",
      "클레스명 : Numpy, Pandas 배워서 파이썬 제대로 사용하기 | 진행률 : 9/57\n",
      "클레스명 : 파이썬 배울 때 이것만은 꼭 알고가자! Py린이를 위한 코딩 입문 | 진행률 : 10/57\n",
      "클레스명 : 초보자 머신러닝/딥러닝 시작하기 | 진행률 : 11/57\n",
      "클레스명 : 인공지능 개발을 위한 파이썬 고성능 컴퓨팅 | 진행률 : 12/57\n",
      "클레스명 : 하루에 1% 수익률! 인공지능 주식 로봇 만들기 | 진행률 : 13/57\n",
      "클레스명 : [SQL / Tableau / Power BI] 현업에 필요한 데이터 분석 Skill | 진행률 : 14/57\n",
      "클레스명 : [합격 사업계획서 작성법] 대출X 갚지 않는 정부지원금 받는 정부지원사업으로 리스크 없이 사업하자! 예비창업자 창업자 자영업자 가능 | 진행률 : 15/57\n",
      "클레스명 : [Online] 비전공자도 즉시 써먹는 데이터분석 & 시각화 실습! 'R | 진행률 : 16/57\n",
      "클레스명 : [사회과학] 논문 통계/연구방법론 1:1 맞춤 튜터링 (SPSS, AMOS) - 온라인가능 | 진행률 : 17/57\n",
      "클레스명 : 구글 AI인증 강사에게 배우는 파이썬, 머신러닝, 구글AI자격증 입문 수업 | 진행률 : 18/57\n",
      "클레스명 : [수업 개편!] 입.문.즉.시. 데이터 분석 레퍼런스 쌓기 #캐글 대회 | 진행률 : 19/57\n",
      "클레스명 : 심리통계 개인과외, 심리학과 대학원 입시(학업계획서, 논문리딩) | 진행률 : 20/57\n",
      "클레스명 : [금융x파이썬] 주식투자전략&백테스트를 기초 코딩으로 구현해 투자하자! | 진행률 : 21/57\n",
      "클레스명 : 딥러닝을 이용한 자연어처리 | 진행률 : 22/57\n",
      "클레스명 : [R중급] 심리/교육 통계 프로젝트가 막힌다면?! | 진행률 : 23/57\n",
      "클레스명 : (데이터공방) 이제는 엑셀말고 파이썬으로, \"파이썬 데이터 분석&시각화 하기\" | 진행률 : 24/57\n",
      "클레스명 : 사회과학 응급 통계 분석/연구설계 코칭 LIVE | 진행률 : 25/57\n",
      "클레스명 : 미국박사: 논문 통계분석 (SPSS, AMOS, MPLUS, EQS) | 진행률 : 26/57\n",
      "클레스명 : [PDF파일]경쟁사와의 웹사이트 비교 분석 및 구글 검색엔진 최적화(SEO)진단해 드립니다 | 진행률 : 27/57\n",
      "클레스명 : 과학고,서울대 출신, 자격증다수보유! 데이터분석,Python,R,SQL 가르쳐드립니다. | 진행률 : 28/57\n",
      "클레스명 : [이론/실무]# 인공지능 # 딥러닝 # A.I 모델을 만들어보자! | 진행률 : 29/57\n",
      "클레스명 : 전공자가 진행하는 통계과외 | 진행률 : 30/57\n",
      "클레스명 : 기초부터 배우는 R 프로그래밍 | 진행률 : 31/57\n",
      "클레스명 : 실전 예제로 배우는 SQL | 진행률 : 32/57\n",
      "클레스명 : [SQL] 누구의 도움 없이 혼.자.서. 데이터 실컷 뽑자! | 진행률 : 33/57\n",
      "클레스명 : [9월 반 모집중][現데이터분석가]문과를 위한 데이터 분석 | 진행률 : 34/57\n",
      "클레스명 : [창업/스타트업] 3년차 젊은 창업자가 알려드리는 '생각을 매출로 만드는 공식!' 모든 잘되는 사업들이 해왔던 공통, 기본 사업공식을 알려드려요! | 진행률 : 35/57\n",
      "클레스명 : 이미지와 텍스트 추출 및 DB 관리를 위한 웹크롤링 및 분석 실무 | 진행률 : 36/57\n",
      "클레스명 : R데이터 분석/시각화 원데이 클래스! | 진행률 : 37/57\n",
      "클레스명 : MATLAB으로 배우는 통계, 베이즈 통계 (기계학습 이론) | 진행률 : 38/57\n",
      "클레스명 : [3회완성][데이터분석/딥러닝] 우버 출신 연구원과 함께하는 데이터분석과 딥러닝 | 진행률 : 39/57\n",
      "클레스명 : 파이썬&데이터분석 나만의 포토폴리오까지, 비전공자도 커리어전환! | 진행률 : 40/57\n",
      "클레스명 : [R코딩/R Studio] R로 배우는 데이터분석! 나도 코딩 전문가! | 진행률 : 41/57\n",
      "클레스명 : [R studio] 데이터사이언스, 시작은 통계 분석부터! | 진행률 : 42/57\n",
      "클레스명 : 데이터 추출 요청은 그만, 3시간 만에 활용하는 SQL | 진행률 : 43/57\n",
      "클레스명 : [1:1 수업] 파이썬을 활용한 엑셀 업무 자동화 #반복업무 싫어요 #정시퇴근할래요 | 진행률 : 44/57\n",
      "클레스명 : 머신러닝을 위한 기초 수학 1달 속성코스(수포자 환영) | 진행률 : 45/57\n",
      "클레스명 : [R/데이터/실무] 입사 전에 배우는 가장 실전적인 R : 데이터 처리 및 분석 / 엑셀과의 작별... | 진행률 : 46/57\n",
      "클레스명 : [Tableau] 오늘 배워서 내일 실무에 적용하는 태블로! | 진행률 : 47/57\n",
      "클레스명 : DataScience부터 최신 AI 트렌드 정리 | 진행률 : 48/57\n",
      "클레스명 : 중요한건 '통계학적 사고'다 | 진행률 : 49/57\n",
      "클레스명 : [4주 완성] 문과생도 할 수 있다! 쉽게 배우는 머신러닝/데이터 사이언스 | 진행률 : 50/57\n",
      "클레스명 : 기본부터 실무까지 구글애널리틱스(GA) 1Day 완벽정복 | 진행률 : 51/57\n",
      "클레스명 : 데이터 분석 & 시각화 ( with R ) | 진행률 : 52/57\n",
      "클레스명 : 실무 개발자에게 배우는 파이썬과 머신러닝 기초 (AI/인공지능/딥러닝/프로그래밍/데이터분석) | 진행률 : 53/57\n",
      "클레스명 : [원데이] 빅데이터를 활용한 시뮬레이션 모델링 | 진행률 : 54/57\n",
      "클레스명 : S그룹인재원 주관 핵심인재 대상 4년 연속 진행된 [데이터 사고력 & 스토리텔링] 원데이 강의 | 진행률 : 55/57\n",
      "클레스명 : DataScience부터 최신 AI 트렌드 정리 | 진행률 : 56/57\n",
      "클레스명 : 기초통계 이론과 함께하는 R 데이터 분석(시각화, 전처리) | 진행률 : 57/57\n",
      "클레스 가격 정보 수집이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "prices_perH,prices =Scraper.scrap_price(titles,links) # 링크를 순회하며 가격정보를 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도서 리스트를 csv파일로 저장하였습니다. 저장 경로는 현재 실행 위치입니다.\n"
     ]
    }
   ],
   "source": [
    "df = Scraper.make_df('DataScience', links, titles, enrolls, prices, prices_perH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/taling_scraper.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
